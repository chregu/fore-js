"use strict";Object.defineProperty(exports,"__esModule",{value:!0});var e=require("axios"),t=require("uuid"),r=require("humps");function s(e){return e&&"object"==typeof e&&"default"in e?e:{default:e}}var i=s(e),n=s(r);const o="default";exports.Foresight=class{constructor({apiToken:e,apiUrl:t="https://foresight-gateway.foreai.co",uiUrl:r="https://foresight.foreai.co",maxEntriesBeforeAutoFlush:s=10,axiosInstance:o}){this.apiToken=e,this.apiUrl=t,this.uiUrl=r,this.maxEntriesBeforeAutoFlush=s,this.axiosInstance=o||i.default.create(),this.timeoutSeconds=60,this.tagToLogEntries={},this.logging=console,this.logging.info("Foresight client initialized"),this.axiosInstance.interceptors.response.use((e=>{const t=e.config.url;if(t&&["/api/eval/run/queries"].some((e=>t.includes(e))))return e;if(e.data)try{e.data=(r=e.data,n.default.camelizeKeys(r,((e,t,r)=>e===e.toUpperCase()?e:t(e,r))))}catch(e){}var r;return e}))}async _makeRequest({method:e,endpoint:t,params:r=null,inputJson:s=null}){try{return(await this.axiosInstance.request({method:e,url:`${this.apiUrl}${t}`,headers:{Authorization:`Bearer ${this.apiToken}`},params:r,data:s,timeout:1e3*this.timeoutSeconds})).data}catch(e){throw e.response&&this.logging.error("api:error:",`${e.response.status} : ${e.response.statusText}`),e}}async createSimpleEvalset({evalsetId:e,queries:r,referenceAnswers:s=null}){try{if(null==e||null==r)throw new Error("evalsetId and queries are required.");if(s&&r.length!==s.length)throw new Error("Number of queries and references must match.");const i={evalset_id:e,evalset_entries:r.map(((e,r)=>({query:e,reference_answer:s?s[r]:null,entry_id:t.v4()})))},n=await this._makeRequest({method:"post",endpoint:"/api/eval/set",inputJson:i});return this.logging.info(`Eval set with evalsetId ${e} created.`),n}catch(e){const t=e.message;throw this.logging.error("createSimpleEvalset:error:",t),new Error(t)}}async getEvalset({evalsetId:e}){try{return await this._makeRequest({method:"get",endpoint:"/api/eval/set",params:{evalset_id:e}})}catch(e){const t=e.message;throw this.logging.error("getEvalset:error:",t),new Error(t)}}async getEvalrunQueries({experimentId:e}){try{return await this._makeRequest({method:"get",endpoint:"/api/eval/run/queries",params:{experiment_id:e}})}catch(e){const t=e.message;throw this.logging.error("getEvalrunQueries:error:",t),new Error(t)}}async createEvalrun({runConfig:e}){try{const t=await this._makeRequest({method:"post",endpoint:"/api/eval/run",inputJson:{evalset_id:e.evalsetId,experiment_id:e.experimentId,metrics:e.metrics}});return this.logging.info(`Eval run with experimentId ${e.experimentId} created.`),t}catch(e){const t=e.message;throw this.logging.error("createEvalrun:error:",t),new Error(t)}}async generateAnswersAndRunEval({generateFn:e,runConfig:t,batchSize:r=10}){try{await this.createEvalrun({runConfig:t});const s=t.experimentId,i=await this.getEvalrunQueries({experimentId:s});if(!i)return void this.logging.error("No queries found for experimentId: %s",s);const n={};for(const[t,r]of Object.entries(i)){const{generatedResponse:s,contexts:i}=e(r);n[t]={generated_response:s,contexts:i}}let o;for(let e=0;e<Object.keys(n).length;e+=r){const t={experiment_id:s,entry_id_to_inference_output:Object.fromEntries(Object.keys(n).slice(e,e+r).map((e=>[e,n[e]])))};o=await this._makeRequest({method:"put",endpoint:"/api/eval/run/entries",inputJson:t})}return this.logging.info("Eval run started successfully. Visit %s to view results.",this.uiUrl),o}catch(e){const t=e.message;throw this.logging.error("generateAnswersAndRunEval:error:",t),new Error(t)}}async flush(){try{if(!Object.values(this.tagToLogEntries).some((e=>e.length>0)))return void this.logging.info("No log entries to flush.");let e;for(const[t,r]of Object.entries(this.tagToLogEntries)){const s={log_entries:r};t!==o&&(s.experiment_id_prefix=t),e=await this._makeRequest({method:"put",endpoint:"/api/eval/log",inputJson:s}),this.logging.log("Log entries flushed successfully for tag %s. Visit %s to view results.",t,this.uiUrl),this.tagToLogEntries[t]=[]}return e}catch(e){const t=e.message;throw this.logging.error("flush:error:",t),new Error(t)}}async log({query:e,response:t,contexts:r,tag:s}){try{const i={query:e,inference_output:{generated_response:t,contexts:r}};s=s||o;const n=this.tagToLogEntries[s]||[];this.tagToLogEntries[s]=[...n,i],this.tagToLogEntries[s].length>=this.maxEntriesBeforeAutoFlush&&await this.flush()}catch(e){const t=e.message;throw this.logging.error("log:error:",t),new Error(t)}}async getEvalrunDetails({experimentId:e,sortBy:t="input.query",limit:r=100}){try{const s={experiment_id:e};return null!==r&&null!==t&&(s.sort_field_name=t,s.limit=r.toString()),await this._makeRequest({method:"get",endpoint:"/api/eval/run/details",params:s})}catch(e){const t=e.message;throw this.logging.error("getEvalrunDetails:error:",t),new Error(t)}}async getEvalrunSummaries({evalsetId:e,experimentIdContains:t,sortBy:r="creation_time",sortAscending:s=!1,limit:i=50,offset:n=0}={}){try{const o={};return e&&(o.evalset_id=e),t&&(o.experiment_id_contains=t),null!==i&&null!==r&&(o.sort_field_name=r,o.sort_ascending=s,o.limit=i.toString(),o.offset=n.toString()),await this._makeRequest({method:"get",endpoint:"/api/eval/run/summaries",params:o})}catch(e){const t=e.message;throw this.logging.error("getEvalrunSummaries:error:",t),new Error(t)}}},exports.MetricType={GROUNDEDNESS:"GROUNDEDNESS",SIMILARITY:"SIMILARITY"};
